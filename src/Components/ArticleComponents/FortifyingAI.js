const FortifyingAI = () => {
  return (
    <div className="p-3 container-fluid">
      <div className="text-center">
        <h1 className="text-primary my-4">
          {" "}
          Fortifying AI- 'Doughnut of Defense': one cannot secure what remains
          unseen
        </h1>
      </div>
      <div className="text-center">
        <img
          style={{ width: "60%", height: "30%", margin: "50px" }}
          src="https://media.licdn.com/dms/image/v2/D5612AQHZw69oP6kmcg/article-cover_image-shrink_720_1280/B56Zdpf54cG0AI-/0/1749821667554?e=2147483647&v=beta&t=4wOktOWG7meMVfcw88fBM-LecJPIrPKD7_k_U5_2PQY"
          alt=""
        />
      </div>

      <div className="row">
        <div className="col-xs-2 col-sm-2 col-lg-2"></div>

        <div
          className="col-xs-8 col-sm-8 col-lg-8 "
          style={{ textAlign: "justify", textJustify: "inter-word" }}
        >
          <h6>
            As Artificial Intelligence (AI) rapidly integrates into the core of
            our digital operations, a critical question emerges: how robust are
            the protective layers surrounding this central intelligence? While
            AI stands as the undisputed core of modern innovation, its
            surrounding defenses often fall short. This article, inspired by
            insightful content from IBM Technology, proposes a comprehensive
            "Doughnut of Defense" strategy to secure AI implementations,
            particularly in the context of web application vulnerabilities.
          </h6>
          <br />
          <h5>
            ðŸŽ¯ The Four Pillars of AI Security: Discover, Assess, Control, and
            Report
          </h5>
          <p>
            To effectively safeguard AI, we must establish four fundamental sets
            of capabilities: Discover, Assess, Control, and Report. Each pillar
            addresses distinct facets of AI security posture management,
            ensuring a holistic and proactive defense mechanism.
          </p>

          <h5>1. Discover: Unveiling the AI Landscape</h5>
          <p>
            Effective security begins with comprehensive visibility. The initial
            step is to{" "}
            <b>discover all instances of AI deployment within an environment</b>
            , spanning across various cloud platforms and on-premises
            infrastructure. This includes not only known, inventoried AI uses
            but, critically, identifying <b>"shadow AI"</b>â€”unauthorized or
            unknown AI implementations. The principle is clear: one cannot
            secure what remains unseen.
          </p>

          <p>
            Beyond mere identification, continuous observation is paramount.
            This involves collecting and examining logs generated by AI systems,
            ideally consolidating them into a vast, open data lake. Such a
            centralized repository facilitates advanced searching, enabling
            proactive threat management and deeper security insights. The
            ability to discover and subsequently observe allows for a critical
            "drilling down" into potential vulnerabilities, enhancing overall
            security efficacy.
          </p>

          <h5>2. Assess: Proactive Vulnerability Management</h5>

          <p>
            The next layer of defense involves a{" "}
            <b>rigorous assessment of the AI environment</b> for vulnerabilities
            and misconfigurations. This encompasses:
          </p>

          <p>
            âœ… <b>AI Security Posture Management (AI SPM):</b> Continuously
            scanning for known vulnerabilities and misconfigurations, with the
            potential for automated remediation. This ensures that any
            deviations from security policies are promptly identified and
            corrected, bringing shadow AI instances into compliance.
          </p>

          <p>
            âœ… <b>Model Scanning and Penetration Testing (Pen Testing):</b> As
            organizations increasingly integrate pre-trained models from
            third-party vendors or open-source platforms (such as Hugging Face,
            which hosts millions of models), the risk of importing malicious or
            vulnerable models escalates. It is impractical, if not impossible,
            to manually inspect the vast number of available models. Therefore,
            automated scanning of these models for malware and security flaws,
            akin to traditional software scanning, is essential. Furthermore,
            conducting penetration tests on AI models helps preemptively
            identify weaknesses that malicious actors might exploit, ensuring
            the system's resilience before it faces real-world attacks.
          </p>

          <h5>3. Control: Implementing Robust Safeguards</h5>

          <p>
            Effective control mechanisms are vital to mitigate identified risks.
            Key control capabilities include:
          </p>

          <p>
            âœ… <b>AI Gateway:</b> Implementing an AI gateway serves as a crucial
            intermediary between users and the AI system. This gateway evaluates
            incoming prompts, distinguishing legitimate requests from malicious
            attempts such as <b>prompt injection attacks.</b> The Open Worldwide
            Application Security Project (OWASP) identifies prompt injection as
            the leading attack vector against generative AI and large language
            models. By proxying all requests through this gateway, organizations
            can detect and block these social engineering attacks, safeguarding
            the AI's integrity. The gateway can be configured for monitoring
            (for new deployments to avoid business interruption) or active
            blocking once confidence in control effectiveness is established.
          </p>

          <p>
            âœ… <b>Guard Rails and Jailbreak Prevention:</b> Establishing robust
            guard rails is essential to prevent "jailbreaking" â€“ attempts to
            force the AI to perform actions outside its intended parameters or
            violate safety rules. The AI gateway or similar control points can
            enforce these rules.
          </p>

          <p>
            âœ… <b>Privacy Violations Prevention:</b> With AI often handling
            sensitive data, guarding against privacy violations e.g., exposure
            of Personally Identifiable Information (PII), Personal Health
            Information (PHI), or company confidential data (CCI) is paramount.
            Controls must be in place to ensure that sensitive information does
            not inadvertently exit the environment.
          </p>

          <h5>4. Report: Enabling Informed Risk Management and Compliance</h5>
          <p>
            The final pillar, <b>Reporting</b>, is fundamental for informed
            decision-making and accountability.
          </p>

          <p>
            âœ… <b>Risk Management Dashboards:</b> Organizations require
            comprehensive dashboards that visualize all discovered risks. These
            dashboards should prioritize vulnerabilities, allowing security
            teams to understand the criticality and impact of various threats. A
            centralized view enables double-clicking into specific issues for
            deeper analysis and swift resolution. This provides the necessary
            insights for effective prevention, detection, and response.
          </p>

          <p>
            âœ… <b>Compliance and Audit Reporting:</b> Adherence to regulatory
            frameworks (e.g., MITRE AI Risk Management Framework) and internal
            security policies is non-negotiable. The ability to generate audit
            reports and demonstrate compliance against established guidelines
            (such as the OWASP Top 10 for AI) is crucial for proving the
            system's integrity and operational adherence to security standards.
          </p>

          <hr />

          <h6>
            By integrating these four critical capabilitiesâ€”Discover, Assess,
            Control, and Reportâ€”organizations can establish a comprehensive
            "Doughnut of Defense" around their AI systems. This layered security
            approach ensures that AI, while at the center of innovation, remains
            robust, resilient, and, indeed, unbreachable.
          </h6>
        </div>
        <div className="col-xs-2 col-sm-2 col-lg-2"></div>
      </div>
      <div className="text-center p-1 my-5 ">
        <p>
          <small>Â© 2019-2025 DVANTAGEPOINT LIMITED</small>
        </p>
      </div>
    </div>
  );
};

export default FortifyingAI;
